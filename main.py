import os
import sys
import cv2
import numpy as np
import torch
import imageio
import math
from argparse import Namespace
from collections import OrderedDict

# å°† RAFT ä»“åº“æ·»åŠ åˆ° Python æ¨¡å—æœç´¢è·¯å¾„ä¸­
sys.path.append('./RAFT/core')
sys.path.append('./RAFT')

from raft import RAFT
from utils.utils import InputPadder

# æ ¹æ®æœ¬åœ°è®¾å¤‡æƒ…å†µé€‰æ‹© deviceï¼ˆM1Pro å»ºè®®ä½¿ç”¨ mpsï¼Œå¦‚æœå¯ç”¨ï¼Œå¦åˆ™ä½¿ç”¨ cpuï¼‰
if torch.cuda.is_available():
    device = "cuda"
elif torch.backends.mps.is_available():
    device = "mps"
else:
    device = "cpu"
print(f"Using device: {device}")

# ---------------------------
# åŠ è½½ RAFT é¢„è®­ç»ƒæ¨¡å‹
# ---------------------------
def load_raft():
    args = Namespace(small=False, mixed_precision=False, alternate_corr=False)
    model = RAFT(args).eval().to(device)
    state_dict = torch.load("raft-things.pth", map_location=device)
    new_state_dict = OrderedDict()
    for k, v in state_dict.items():
        new_key = k.replace("module.", "")
        new_state_dict[new_key] = v
    model.load_state_dict(new_state_dict, strict=False)
    print("âœ… é¢„è®­ç»ƒæƒé‡åŠ è½½æˆåŠŸï¼")
    return model

# ---------------------------
# æå–è§†é¢‘å¸§
# ---------------------------
def extract_frames(video_path, output_folder):
    cap = cv2.VideoCapture(video_path)
    frame_count = 0
    os.makedirs(output_folder, exist_ok=True)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        cv2.imwrite(f"{output_folder}/frame_{frame_count:04d}.png", frame)
        frame_count += 1
    cap.release()
    return frame_count

# ---------------------------
# è®¡ç®—å¸§é—´å·®åˆ†ï¼ˆä»…å¤„ç† ROI åŒºåŸŸï¼‰
# ---------------------------
def frame_difference(frame1, frame2, roi):
    x, y, w, h = roi
    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
    diff = cv2.absdiff(gray1[y:y+h, x:x+w], gray2[y:y+h, x:x+w])
    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)
    frame_diff = np.zeros_like(gray1)
    frame_diff[y:y+h, x:x+w] = thresh
    return cv2.cvtColor(frame_diff, cv2.COLOR_GRAY2BGR)

# ---------------------------
# è®¡ç®— ROI åŒºåŸŸçš„å…‰æµï¼ˆåŸºäº RAFTï¼‰
# ---------------------------
def compute_optical_flow(model, frame1, frame2, roi):
    x, y, w, h = roi
    # è£å‰ª ROI åŒºåŸŸ
    frame1_roi = frame1[y:y+h, x:x+w]
    frame2_roi = frame2[y:y+h, x:x+w]
    # è½¬æ¢ä¸º tensorï¼Œå¹¶è½¬ç½®ä¸º (B, C, H, W)
    frame1_roi = torch.from_numpy(frame1_roi).permute(2, 0, 1).unsqueeze(0).float().to(device)
    frame2_roi = torch.from_numpy(frame2_roi).permute(2, 0, 1).unsqueeze(0).float().to(device)
    padder = InputPadder(frame1_roi.shape)
    frame1_roi, frame2_roi = padder.pad(frame1_roi, frame2_roi)
    with torch.no_grad():
        flow = model(frame1_roi, frame2_roi)[-1].cpu().numpy()[0].transpose(1, 2, 0)
    flow = cv2.resize(flow, (w, h))
    full_flow = np.zeros((frame1.shape[0], frame1.shape[1], 2), dtype=np.float32)
    full_flow[y:y+h, x:x+w, :] = flow
    return full_flow

# ---------------------------
# å¯è§†åŒ–å…‰æµï¼ˆä»…æ˜¾ç¤º ROI åŒºåŸŸï¼‰
# ---------------------------
def visualize_flow(flow, roi):
    x, y, w, h = roi
    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)
    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])
    hsv[y:y+h, x:x+w, 0] = ang[y:y+h, x:x+w] * 180 / np.pi / 2
    hsv[y:y+h, x:x+w, 1] = 255
    hsv[y:y+h, x:x+w, 2] = cv2.normalize(mag[y:y+h, x:x+w], None, 0, 255, cv2.NORM_MINMAX)
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

# ---------------------------
# è®¡ç®—è¿çº¿çš„è§’åº¦ï¼ˆæ»´è½è§’åº¦ï¼‰
# ---------------------------
def calculate_drop_angle(white_pixels, reference_point):
    if not white_pixels:
        return None
    x_coords, y_coords = zip(*white_pixels)
    centroid_x = int(np.mean(x_coords))
    centroid_y = int(np.mean(y_coords))
    centroid_y -= 10  # è´¨å¿ƒä¸Šç§» 10 åƒç´ 
    dx = centroid_x - reference_point[0]
    dy = centroid_y - reference_point[1]
    angle = math.degrees(math.atan2(dy, dx))
    return (centroid_x, centroid_y, angle)

# ---------------------------
# å¤„ç†è§†é¢‘ï¼Œç»Ÿè®¡æ»´è½æ¬¡æ•°ï¼ŒåŒæ—¶è¾“å‡ºå¸¦æ ‡æ³¨çš„è§†é¢‘
# ---------------------------
def process_video(video_path, output_path):
    # æ£€æŸ¥è§†é¢‘èƒ½å¦æ‰“å¼€
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–æ–‡ä»¶æ ¼å¼")
        return {"error": "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶"}
    else:
        print("âœ… è§†é¢‘æ‰“å¼€æˆåŠŸ")
    cap.release()

    frame_folder = "frames"
    if os.path.exists(frame_folder):
        # æ¸…ç©ºæ—§å¸§
        for f in os.listdir(frame_folder):
            os.remove(os.path.join(frame_folder, f))
    else:
        os.makedirs(frame_folder, exist_ok=True)
        
    frame_count = extract_frames(video_path, frame_folder)

    # è®¾å®š ROI åŒºåŸŸå’Œå‚è€ƒç‚¹ï¼ˆè¯·æ ¹æ®å®é™…åœºæ™¯è°ƒæ•´ï¼‰
    roi = (130, 200, 220, 185)
    reference_point = (130, 290)  # è®¡ç®—è§’åº¦çš„å›ºå®šå‚è€ƒç‚¹

    output_frames = []
    drop_count = 0
    last_drop_angle = None
    cooldown_frames = 0
    WHITE_AREA_THRESHOLD = 7000

    # åŠ è½½ RAFT æ¨¡å‹ï¼ˆä»…åŠ è½½ä¸€æ¬¡ï¼‰
    model = load_raft()

    for i in range(frame_count - 1):
        frame1 = cv2.imread(f"{frame_folder}/frame_{i:04d}.png")
        frame2 = cv2.imread(f"{frame_folder}/frame_{i+1:04d}.png")
        if frame1 is None or frame2 is None:
            print(f"âŒ è¯»å–å¸§å¤±è´¥: frame_{i:04d}.png æˆ– frame_{i+1:04d}.png")
            continue

        # è®¡ç®— ROI å†…çš„å¸§é—´å·®åˆ†
        frame_diff = frame_difference(frame1, frame2, roi)

        # ç»˜åˆ¶å‚è€ƒç‚¹ï¼ˆä¾‹å¦‚ç”¨é»„è‰²è¡¨ç¤ºï¼‰
        cv2.circle(frame_diff, reference_point, 5, (0, 255, 255), -1)


        # è·å– ROI å†…ç™½è‰²åƒç´ ç‚¹çš„å…¨å±€åæ ‡
        roi_mask = frame_diff[roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]]
        white_pixels = list(zip(np.where(roi_mask == 255)[1] + roi[0],
                                np.where(roi_mask == 255)[0] + roi[1]))
        white_area = len(white_pixels)
        drop_angle = None
        centroid_x, centroid_y = None, None

        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸€æ¬¡æˆåŠŸæ»´è½
        if white_area > WHITE_AREA_THRESHOLD and cooldown_frames == 0:
            drop_count += 1
            cooldown_frames = 50  # è®¾ç½®å†·å´å¸§æ•°
            result = calculate_drop_angle(white_pixels, reference_point)
            if result:
                centroid_x, centroid_y, drop_angle = result
                last_drop_angle = drop_angle
                print(f"âœ… æˆåŠŸæ»´è½ {drop_count} æ¬¡ï¼Œåœ¨å¸§ {i+1}ï¼Œè§’åº¦: {drop_angle:.2f}Â°")

        if cooldown_frames > 0:
            cooldown_frames -= 1

        # åœ¨å¸§å·®å›¾ä¸Šç»˜åˆ¶ ROI æ¡†åŠæ£€æµ‹ç»“æœ
        cv2.rectangle(frame_diff, (roi[0], roi[1]), (roi[0]+roi[2], roi[1]+roi[3]), (0, 255, 0), 2)
        if drop_angle is not None:
            cv2.circle(frame_diff, (centroid_x, centroid_y), 5, (0, 0, 255), -1)
            cv2.line(frame_diff, reference_point, (centroid_x, centroid_y), (255, 0, 0), 2)
            cv2.putText(frame_diff, f"Angle: {drop_angle:.2f}", (centroid_x+10, centroid_y-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        drop_text = f"Success Drops: {drop_count}"
        if last_drop_angle is not None:
            drop_text += f" | Angle: {last_drop_angle:.2f}"
        cv2.putText(frame_diff, drop_text, (50, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # å¯é€‰ï¼šè®¡ç®—å…‰æµå¹¶è¿›è¡Œå¯è§†åŒ–ï¼ˆæ­¤å¤„å±•ç¤º ROI å†…å…‰æµï¼Œå¯æ ¹æ®éœ€è¦å–æ¶ˆæ³¨é‡Šï¼‰
        # flow = compute_optical_flow(model, frame1, frame2, roi)
        # flow_vis = visualize_flow(flow, roi)
        # combined = np.hstack((frame1, frame_diff, flow_vis))

        # å°†åŸå§‹å¸§å’Œæ ‡æ³¨å¸§æ¨ªå‘æ‹¼æ¥
        combined = np.hstack((frame1, frame_diff))
        output_frames.append(combined)

    # ä¿å­˜å¤„ç†åçš„å¸§ç”Ÿæˆè§†é¢‘
    imageio.mimsave(output_path, output_frames, fps=30)
    print(f"âœ… å¤„ç†å®Œæˆï¼Œè§†é¢‘ä¿å­˜è‡³ {output_path}")
    print(f"ğŸ”¢ æœ€ç»ˆç»Ÿè®¡æˆåŠŸæ»´è½æ¬¡æ•°: {drop_count}")
    return {"output_video": output_path, "drop_count": drop_count}

if __name__ == "__main__":
    # æœ¬åœ°æµ‹è¯•è§†é¢‘è·¯å¾„
    video_path = "./video/test2.mov"
    output_path = "./outputcv.mp4"
    result = process_video(video_path, output_path)
    print(result)
